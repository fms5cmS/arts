
限流是服务提供方为了防止调用方无脑调用压垮自己，保护自身服务高可用的保护机制。在一段时间内，定义某个客户或应用可以接收或处理多少个请求。

# 单机限流

还有固定窗口算法、滑动窗口算法。

## Leaky bucket

> 漏桶算法(Leaky Bucket) 是网络世界中流量整形（Traffic Shaping）或速率限制（Rate Limiting）时经常使用的一种算法，它的主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。

漏桶算法：
1. 一个**固定容量**的漏桶，且水滴以**固定速率流出**
2. 漏桶为空，则不再流出水滴
3. 水滴**流入桶的速率是任意的**
4. 漏桶满了的话，新流入的水滴会溢出（丢弃）

一个固定容量的桶，请求（水滴）以任意速率进来，但以固定的速率来处理请求（水滴），当请求被处理就代表水滴流出了，如果桶满了的话请求就会被丢弃。

Golang 的第三方库实现：[ratelimit](https://github.com/uber-go/ratelimit) 是一个阻塞的漏桶算法实现，如果拿不到 token 的话，请求会阻塞住，直到拿到 token。

## Token bucket

令牌桶算法：
1. 向**固定容量**的桶中以**固定速率添加 token**，满了则不再添加
2. **请求的速率**是任意的，当请求过来后会尝试从桶中取 token
3. 能取到 token，则对请求进行处理，取不到 token，则丢弃请求

一个固定容量的桶，token 以固定速率进入桶中，必须持有 token 才能处理请求，当请求以任意速率过来时，只要桶中有 token 就能以任意速率处理请求，如果没有 token，则请求丢弃。

当桶里面有积攒下来的 token 时，可以应对突发流量。

Golang 的实现：[rate](golang.org/x/time/rate)

## 自适应限流

漏桶、令牌桶算法都需要配置 quota（配额），也就是必须知道服务自身最大的并发数，一般在上线前可以通过压测得到 95th 线或 99th 线，并将其记录在 proto 文件的接口定义中，以供其他服务配置超时。

但由于系统一直在不断迭代，其处理能力也会随之变化，每次上线前都需要进行压测并调整限流参数就会很繁琐！太被动, 不能快速适应流量变化。

因此，需要一种自适应的限流算法，即：**过载保护，根据系统当前的负载自动丢弃流量**。它可以计算系统临近过载时的峰值吞吐作为限流的阈值来进行流量控制，达到系统保护。

**问题 1：怎么判断系统临近过载？**

A：可以根据 CPU、Memory 来判断系统是否处于过载，如 CPU 达到 80% 就认定服务临近过载，而配置 CPU、Memory 的值相比直接配置限流 quota 则很容易。

**问题 2：怎么计算临近过载时的系统吞吐？**

A：可以采用利特尔法则以及统计学的滑动平均算法来计算。

> 利特尔法则（Little’s Law）：L = λW，适用于 稳定的、非抢占式的系统
> L，长期的平均顾客数
> λ，长期的有效到客率
> W，顾客在系统中平均的等待时间
>
> 使用滑动平均是为了去除峰值的影响
> 采用统计学上的滑动平均算法来估算变量的局部均值，使得变量的更新与历史一段时间的历史取值有关，无需记录所有的历史局部变量就可以实现平均值估算

使用一个独立的线程采样，每隔一段时间(如 250ms)触发一次。再计算一段时间内的滑动均值，然后使用 **CPU 的滑动均值**作为启发阈值，一旦触发就进入过载保护阶段。

示例：假设对 5s 内的数据进行采样，CPU 阈值为 800（即 80%），然后使用利特尔法则来计算并发数是否超过当前可承载的最大并发数

```
inflight: 当前服务中正在进行的请求的数量（利特尔法则的 L）
pass：每个采样窗口内成功请求的数量（利特尔法则的 λ）
rt；单个采样窗口中平均响应时间（利特尔法则的 W）

pass * rt < inflight，则正常处理请求，如果 pass * rt > inflight 则丢弃请求。
```

**问题 3：触发过载保护后流量被丢弃，立刻检查此时 CPU，未达到阈值立刻关闭过载保护，但此时负载还未降下来，下个采样窗口发现又触发了过载保护... 导致 CPU 在临界值附近抖动，怎么办？**

加窗口。

CPU 达到临界值，即触发过载保护后，先让它持续 1～2s 的**冷却时间**（持续限流，仍根据上面 pass*rt 和 inflight 的关系来决定是否丢弃请求），冷却时间以后，再判断此时的 CPU 是否达到阈值，看是否持续进入过载保护。

## go-zero

go-zero 的实现见 adaptiveshedder.go，描述详见 [微服务治理之如何优雅应对突发流量洪峰](https://segmentfault.com/a/1190000041001728)，

会对 5s 内的数据进行采样，设置的 CPU 阈值为 900，冷却时间长度为 1s。

在使用滑动均值算法计算 CPU 负载时，历史 CPU 的比重为 0.95，最新 CPU 的比重为 (1-0.95) = 0.05。

# 分布式限流（全局限流）

分布式限流，是为了**控制某个应用全局的流量**，而非真对单个节点纬度。而漏桶算法、令牌桶算法、自适应限流都是针对单个节点的，无法做分布式限流。

使用 Redis 来做分布式限流，每个请求过来后调用 `incr` 命令对计数器自增。而这种每个请求都访问次 Redis 的 pre-request 模式对性能有一定影响，且容易产生 key 的热点。

上面的 Redis 相当于每次仅获取一个 quota，那么是否可以改为每次获取批量 quota，然后单机再使用令牌桶算法来做限制？

- 每次心跳后，异步批量获取 quota， 可以大大减少请求 Redis 的频次，获取完以后本地消费，基于令牌桶拦截。

但是每次申请的 quota 数量又需要手动配置静态值，能否基于单个节点按需申请，且避免出现不公平的现象呢？

初次使用默认值，一旦有过去历史窗口的数据，可以基于历史窗口数据进行 quota 请求。

> 不同节点等价的权利来获取资源，但其中某些节点实际只需要比其他节点少的资源。

- 广泛使用的分享技术称为 最大最小公平分享(Max-Min Fairness)算法，简单来说，公平分享分配给每个用户想要的可以满足的最小需求，然后将没有使用的资源均匀的分配给需要‘大资源’的用户。

> 最大最小公平分享(Max-Min Fairness)算法：
>    资源按照需求递增的顺序进行分配；
>    不存在用户得到的资源超过自己的需求；
>    资源本身是有限的，未得到满足的用户等价的分享资源

# 限流的优先级

更细粒度的限流还需要区分请求、甚至每个用户的每种请求，也就是说需要引入优先级。过载保护时，低优先级的请求先被拒绝掉。

K8s 的 APF(API Priority and Fairness)：
- 细粒度的方式对请求进行分类和隔离；
- 引入了空间有限的排队机制，因此在非常短暂的突发情况下，API 服务 器不会拒绝任何请求；
- 通过使用公平排队技术从队列中分发请求

# 熔断（客户端限流）

拒绝请求也是有成本的，有可能后端忙着不停发送拒绝请求，导致过载。

如果我们的本来流量可以支撑 1w rps，加了限流可以支撑在 10w rps 的情况下仍然可以提供 1w rps 的有效请求，但是流量突然再翻了 10 倍，来到 100w rps，那么服务该挂还是得挂。

可用性的保障需要整个链路上的每个组件都参与，而**客户端上的限流措施是熔断**。熔断的出发点是保护客户端， 不被外部服务的问题所拖累， 永远快速响应（哪怕得到一个错误，也好于长时间等待）。永远避免资源的过度消耗。

熔断器的三个状态：
- 关闭(closed): 关闭状态下没有触发断路保护，所有的请求都正常通行
- 打开(open): 当错误阈值触发之后，就进入开启状态，这个时候所有的流量都会被客户端节流，不允许通过，直接报错
- 半打开(half-open): 处于打开状态一段时间之后，会尝试放行一个流量来探测当前 server 端是否可以接收新流量，如果这个没有问题就会进入关闭状态，如果有问题又会回到打开状态

熔断器是在客户端实现的，所以触发阈值通常有两个因素：QPS、失败率。如 QPS > 50，且失败率大于 30%。 

Go 的第三方库实现：[hystrix-go](https://github.com/afex/hystrix-go)

上面的熔断后会一刀切，客户端所有的流量都会被丢弃！

Google SRE 中的熔断算法核心公式：`max(0, (request - K*accepts)/(requests + 1))`，该公式计算的是请求被丢弃的概率。

> requests，总的请求数
> acceots，成功的请求数
> K，倍率，可配置。K 越小表示越激进，越小表示越容易被丢弃请求

当成功的请求数量越少，K越小的时候的值就越大，计算出的概率也就越大，表示这个请求被丢弃的概率越大，极限情况下，accepts 趋于 0，得到的概率就是 1，会丢弃全部请求。

仅考虑是否被丢弃（需要 max 函数的第二个参数值为负数），而不考虑具体丢弃的概率的话：
如果 K = 1，`request - 1*accepts <= 0` ==> `accepts/requests >= 1`，也就是说请求成功率必须是 100%，才不触发熔断
如果 K = 2，`request - 2*accepts <= 0` ==> `accepts/requests >= 1/2`，也就是说只要请求成功率 >= 50%，才不触发熔断

这种熔断方式只有关闭、打开两种状态，而没有半打开状态。

https://github.com/go-kratos/kratos 中有实现。

# 额外阅读

TCP 的 BBR 算法

[极客时间-高并发架构实战课: 限流器设计](https://time.geekbang.org/column/article/497807)

[go-zero: Go 中实现用户的每日限额（比如一天只能领三次福利）](https://mp.weixin.qq.com/s/s8T1430LS-l3ks9cL7sZyw)

[go-zero: Go 分布式令牌桶限流 + 兜底保障](https://mp.weixin.qq.com/s/ulGRw4qkWbGKdF83VaIb7A)

[Guava令牌桶算法实现源码分析（一）](https://mp.weixin.qq.com/s/IfKt8-p4iTDS9ertr3c70g)

[阿里巴巴-Sentinel: 系统自适应限流](https://github.com/alibaba/Sentinel/wiki/%E7%B3%BB%E7%BB%9F%E8%87%AA%E9%80%82%E5%BA%94%E9%99%90%E6%B5%81)

[限流算法实践](https://www.infoq.cn/article/ipxnuqwu3lgwxc8j7tzw)

[Kubernetes: API 优先级和公平性](https://kubernetes.io/zh/docs/concepts/cluster-administration/flow-control/)

[B站崩溃的背后，b站高可用架构到底是怎么样的](https://zhuanlan.zhihu.com/p/390179811)

