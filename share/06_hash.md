在内存有限的单片机上运行嵌入式程序时，会压缩数据的空间占用，以时间换空间；而在面向海量用户的分布式服务中，通常会使用更多的空间建立索引，换取更快的查询时间。

如果我们需要数据规模上亿后还能提供微妙级的访问速度，那么作为最快的索引，哈希表是第一选择！

哈希表是基于数组实现的，通过哈希函数将查询关键字转换为数组下标，然后利用数组可以根据下标以 O(1) 时间复杂度来随机访问元素的特性从而实现了常量的查询效率。

> 另一种索引"位图"的时间复杂度也是 O(1)，不过其属于哈希表的变种，限制了每个哈希桶只有一个比特位，虽然它消耗的空间更少，但仅用于辅助数据的主索引，快速判断对象是否存在。也常用于解决缓存穿透问题。

在生产环境是用哈希表管理上亿数据，会面临以下问题：

- 为了保证数据可靠性，需要做灾备恢复，可以结合**快照+oplog（操作日志）的方式恢复数据**，但是，内存中的哈希表如何快速序列化为快照文件？
- 直接是用标准库提供的哈希表处理这么大规模的数据，会导致内存消耗过大，因为每多是用一个 8 字节的指针都会被放大亿万倍，该如何实现更节约内存的哈希表？
- 哈希表频繁发生冲突时，速度会急剧降低，该通过那些手段减少冲突概率？

# 内存结构和序列化方案

解决哈希冲突的方法通常有两种：

- 链表法：落在数组同一个位置中的多个数据，通过链表串起来
  - 哈希函数找到数组的位置后，再是用链表遍历的方式查找数据
- 开放寻址法：插入时如果数组对应的位置已经占用，会按既定规则变换哈希函数计算出下一个数组下标，直到找到空闲的位置

链表法实现简单，且允许存放元素个数大于数组大小（即装载因子大于 1），但是序列化数据的代价很大，因为是用了指针后，内存是不连续的！

> 装载因子 = 填入表中的元素个数/哈希表的长度。装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。

开放寻址法确保所有对象都在数组中，就可以把数组用到的这段连续内存原地映射到文件中，再通过备份文件的方式就可以实现哈希表的备份。而新进程启动时，也可以通过映射磁盘中的文件到内存中，从而快速构建哈希表提供服务。

> 链表的数据在内存中不连续，序列化时必须遍历所有的元素，把每个元素的值序列化写入到另一段内存中
> 
> 而当数据在内存中连续时，可以直接把内存复制到磁盘上，或发送到网卡上，不用重新耗费 CPU 进行一次编码，先将分散的内存信息转换到一块连续内存中。

如果可以将数据完整放入数组，那么开放寻址法就解决了序列化的问题。但是，由于开放寻址法的冲突概率越低，空桶的比例也就越高（装载因子越小），而如果每个空桶都占用上百字节（每条数据的长度），亿级数据会轻松把浪费的内存放大许多倍。

所以，**为了尽可能少的浪费内存，需要把数据从哈希表中分离出来**，提升哈希表的灵活性（即，可以灵活调整装载因子），该方法也算是开放寻址法。那么又该如何序列化哈希表外的数据呢？

可以像开放寻址法那样，**使用定长数组存放对象，通过原地映射文件的方式来序列化数组**。由于对象未必是定长的，所以又可以分为以下两种情况：

- 对象长度固定

额外使用一个数组 D 来存储对象，而哈希桶中存放 D 的下标。如果哈希表是动态的，支持新建、删除操作，还需要把 D 中空闲的位置构建成一个单链表，新建时从链表头部取一个位置来存放元素，删除时将该位置归还至链表的头部。

- 对象长度不固定

可以采用有限个定长数组存储对象，用以空间换时间的思想加快访问速度。如数组 D1 存储长度小于 L1 的对象，D2 存储长度介于 L1 和 L2 的对象，以此类推。

而哈希桶通过二进制位来找到存放对象的位置，每个同用前 i 位存放对象在哪个数组中，用后 j 位存放数组的下标。查找数据时，前 i 位找到 D1 或 D2 数组，后 j 位作为数组下标直接访问数组指定位置的对象。

# 哈希函数&动态扩容

- 哈希函数

哈希函数的基数必须是素数！哈希函数计算出的哈希值要尽可能随机且分布均匀。

当哈希函数把高信息量的关键字压缩成更小的数组下标时，一定会丢失信息，所以为了尽量多的保留区分度高的信息，需要分析关键字的特点、分布规律。如 11 位手机号，前 3 位网络识别号（区分运营商）的区分度度最差，中间 4 位地区编码的信息量有所增强，最后 4 位用户号码的信息量最高，如果哈希桶只有 1w 个，那么通过 phoneNumber%10000 来最大化保留后四位信息就是个不错的选择。

- 动态扩容

装载因子越接近 1，冲突概率就越大，由于对象数量无法改变，只能通过扩容提升哈希桶的数量，减少冲突。

哈希表的扩容会影响哈希桶大小，进而影响哈希函数，扩容后所有元素的存放位置都需要重新计算（即 rehash），所以扩容是一个及其耗时的操作。如何在扩容过程中持续提供正常服务呢？

可以将一次性的数据迁移过程分为多次后台迁移，且提供服务时要能根据迁移情况选择新老哈希表即可。

# Redis 中的哈希表

## 全局哈希表

Redis 是一个键值数据库，值的常用数据类型包括 String、List、Hash、Set、Sorted Set，而为了实现从键到值的快速访问，键值之间则是使用了全局哈希表来保存。

全局哈希表解决哈希冲突的方式是链表法。为了解决哈希冲突后链表长度过长导致查找效率降低的问题，Redis 会对哈希表做 rehash 操作，让逐渐增多的元素能在更多的桶之间均匀分布，减少单个桶中的元素数量，从而减少单个桶中的冲突。

Redis 默认是用了两个全局哈希表，假设分别为 A、B，一开始插入数据时，默认使用 A，此时 B 并未被分配空间，随着数据逐渐增多，Redis 开始执行 rehash：

1. 给 B 分配更大空间
2. 把 A 中的护具重新映射并拷贝到 B 中
3. 释放 A 的空间

之后，就可以从 A 切换到 B，用扩容后的 B 保存更多数据，而 A 留作下一次 rehash 扩容备用。

为了避免在第 2 步拷贝数据时，大量操作阻塞 Redis 线程，影响其他请求，Redis 采用了渐进式 rehash：在第 2 步拷贝数据时，Redis 仍正常处理客户端请求，每处理一个请求时，从 A 中的第一个索引位置开始，顺带着将这个索引位置上链表的所有元素 拷贝到 B 中；等处理下一个请求时，再顺带拷贝 A 中下一个索引位置的元素。

## 值类型-Hash

Redis 的值类型 Hash 有两种实现方式，一种是哈希表，和全局哈希表的原理相同，另一种是压缩列表。

压缩列表是 Redis 为了节约内存而开发的，**由连续内存块组成的顺序型数据结构**，类似于数组。不同于数组的是，压缩列表在表头有三个字段分别用于表示列表占用的字节数、列表尾部偏移量、列表中元素个数，同时在表尾还有一个标识列表结束的字段（固定值为 0xFF）。

> 最新的 Redis 将压缩列表替换成了 listpack

压缩列表仅用于保存元素不多的场景，当元素过多时就会使用哈希表来保存数据了。

> hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数
> 
> hash-max-ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度
> 
> 以上两个阈值只要超过任意一个，Hash 类型就会使用哈希表来保存数据了。

# Golang 的 map

> Go 中 map 不支持并发读写是为了保证大多数场景下的查找效率，但要求 map 操作并发安全只会增加少数程序的安全性。

```go
package runtime

import "unsafe"

// map 的底层结构
type hmap struct {
  count      int            // 元素的个数，len(map) 的返回值
  flags      uint8          // map 的状态，是否正在写入
  B          uint8          // 桶(buckets)数组的长度为 2^B 个，map 共计存放 loadFactor * 2^B 个元素
  noverflow  uint16         // 溢出桶的数量
  hash0      uint32         // hash seed，生成 hash 的随机数种子
  buckets    unsafe.Pointer // 指向一个 2^B 大小的桶数组
  oldbuckets unsafe.Pointer // 扩容时用于保存之前的 buckets，大小为当前 buckets 的一半，数据全部转移到新桶后，旧桶会被清空
  nevacuate  uintptr        // 标识迁移进度，小于该地址的 buckets 已经完成迁移
  extra      *mapextra      // optional fields，存储溢出桶
}

// buckets 字段是地址，指向了 []bmap，也就是桶数组的起始位置！bmap 是每个桶的结构
type bmap struct {
  // tophash 是 key 的 hash 值的高 8 位
  // 通过比较不同 key 的 hash 值高 8 位可以减少访问键值对次数以提高性能
  tophash [8]uint8
}

type mapextra struct {
  overflow    *[]*bmap // 保存了所有的溢出桶，如果赋值过程中申请内存创建了新的溢出桶，还会将新的溢出桶地址记录到这里
  oldoverflow *[]*bmap // 旧的溢出桶，重建过程中会将上面 overflow 的地址存储到这里，并抗 overflow 置为 nil

  nextOverflow *bmap // 指向空闲的溢出桶的指针
}
```

尽管 `bmap` 结构中并没有定义 key、value，但是 map 在编译期阶段就可以确定 key、value 及桶的大小，会将 `bmap` 的结构动态扩展为：

```go
// 对应的存储结构类似于： 
// [hash0, hash1, hash2, hash3, hash4, hash5, hash6, hash7]
// [key0,  key1,  key2,  key3,  key4,  key5,  key6,  key7 ]
// [val0,  val1,  val2,  val3,  val4,  val5,  val6,  val7 ]
type bmap struct {
	tophash  [8]uint8
	keys     [8]keyType
	values   [8]valueType
	overflow uintptr // 溢出桶的指针
	// 还有其他字段
}
```

可以看出，**Go 中的 map 将 key 和 value 分开存储了，而不是按照 {key, value}, {key, value} 的形式存储，这样做是为了在字节对齐时压缩空间**。

在进行查找操作时，先对 key 进行哈希计算得到 hash，根据 hash 的低位先找到桶的位置，然后遍历桶的 `tophash` 数组，如果数组元素的值与计算出的 hash 的高 8 位相同，也就得到了数组的下标，接下来就可以通过数组下标找到对应的 key、value，然后比较 key。

Go 中还有一个溢出桶的概念，在进行赋值操作时，如果桶中的数据超过了 8 个，并不会直接开辟一个新桶，而是将数据放到该桶对应的溢出桶 `bmap.overflow` 中。正常情况下，数据很少会跑到溢出桶中。

同理，在进行查找操作时，如果 key 的 hash 的高 8 位并不在指定桶的 `tophash` 数组中，那么就需要遍历该桶对应的溢出桶 `bmap.overflow` 的数据了。

在 `hmap` 结构中还有一个 `extra` 字段也是用来存储溢出桶的，只有在最开始初始化 map 的数量较大时，才会提前创建好一些溢出桶放到 `hmap.extra` 中。这样，当发生溢出时，可以直接使用提前创建好的桶，直到预分配的溢出桶是用完了，才会新建溢出桶。

当发生以下两种情况之一时，会触发 map 的重建，且重建方式不同：

- map 的负载因子超过了 6.5：map 会进行扩容，增大到旧 map 的两倍大小
- 溢出桶数量过多：map 只会新建和原来相同大小的桶
  - 由于对 map 的操作既有插入又有删除，导致很多桶出现了空洞，这样的话查找效率会降低

## 创建

创建 map 的语法：

- `m := make(map[string]string)` 
- `m := make(map[string]string, 8)`，指定长度
- `var m map[string]string`，此时 m == nil，无法向其中添加元素，会 panic

底层实际调用了 `runtime.makemap()` 函数，用于初始化 `hmap` 结构体各个字段，如果桶的数量为 0，那么桶数组会在赋值的时候再分配内存。

> `runtime.makemap()` 的返回值是 `*hmap` 指针类型，Go 的函数传参都是值传递，在函数内部，参数会被 copy 到本地，而 `*hmap` copy 完成后仍指向同一个 map，因此函数内部对 map 的操作会影响到原本的 map。

## 查询

- `v := m[key]` 底层实际调用了 `runtime.mapaccess1()` 
- `v, ok := m[key]` 底层实际调用了 `runtime.mapaccess2()`

两个函数的逻辑基本一致，主要逻辑有(其中 h 变量是 `hmap` 类型)：

- `h.flags&hashWriting`通过按位与操作，判断是否进行并发读写操作
- `hash := t.hasher(key, uintptr(h.hash0))` 计算 hash 值，并加入 h.hash0 引入随机性
- 计算 m（详见代码），假设 h.B = 5，则 m = 31，对应的二进制全是 1
- `b := (*bmap)(add(h.buckets, (hash&m)*uintptr(t.bucketsize)))` 定位到目标桶
  - hash&m 进行按位与操作，也就是说根据 hash 值的低位来计算这个 hash 值会落在第几个桶中
  - h.buckets 是桶数组的起始地址，桶的位置*每个桶的size 得到偏移量，从起始位置开始指针移动偏移量，从而得到目标桶的起始地址，也即 `bmap` 结构，同样也是 `bmap.tophash` 数组的起始地址
- 如果 `h.oldbuckets != nil` 说明发生了扩容，需要先从旧的桶数组中找到目标桶，所以会更新 b 的值
- `top := tophash(hash)` 计算高 8 位的 hash
- 遍历目标桶 b
  - 根据 top 值遍历 `b.tophash` 数组，从而定位到 key 和 value 在数组中的下标位置
  - 如果 key 存储的是指针，需要解引用
  - 如果 key 值相等，返回 value（如果 value 中存储的也是指针，同样需要解引用）
- 如果目标桶 b 中还是没有找到，那么还需要遍历目标桶的溢出桶 `b.overflow`，遍历逻辑同上
- 还是没有找到，返回值类型的零值

## 赋值

- `m[key] = value` 底层实际调用了 `runtime.mapassign()` 

主要逻辑有（其中 h 变量是 `hmap` 类型）：

- `h.flags ^= hashWriting` 通过异或操作，更新 map 的状态为正在写入
- 当前 `h.buckets == nil`，需要创建一个新桶
- 根据 hash 的低位找到目标桶的位置 bucket（注意，这是目标桶的位置）
- 判断桶是否正在重建，如果是的话，**优先完成当前目标桶的重建过程**（详见后）`growWork(t, h, bucket)`
- 定位到目标桶 b，定位过程与查询过程的定位过程相同
- 计算高 8 位的 hash 值
- 遍历目标桶 b，遍历过程与查询过程中的遍历过程相同，如果 b 中没有找到，也会遍历目标桶的溢出桶，找到插入的位置
- 如果当前 map 尚未开始重建，判断负载因子过大或溢出桶数量过多，两者满足其中一个条件就触发 map 的重建 `hashGrow(t, h)`，重建完成后重新开始找桶的位置及插入位置
- 如果桶中没有空的位置（这里是指目标桶和原溢出桶都没有位置），则创建新的溢出桶，将 key、value 放入其中，且 `h.count++`
  - `newb := h.newoverflow(t, b)` 会先从 `b.extra` 中获取溢出桶，没有的话才会申请新的内存
- 最后，还需要再次判断 map 是否正在写入状态，如果是，则报错；如果不是，`h.flags &^= hashWriting` 通过按位置零的操作，更新 map 状态为并不是正在写入

## 重建

从上面赋值的过程中可以看出，当发生以下两种情况时会触发 map 的重建 `runtime.hashGrow()`：

- map 的负载因子超过了 6.5
- 溢出桶数量过多（由于对 map 的操作既有插入又有删除，导致很多桶出现了空洞，这样的话查找效率会降低）

主要逻辑有：

- 如果触发原因是由于溢出桶数量过多，`bigger = 0`；如果触发原因是由于负载因子过大，则 `bigger = 1`
  - 在 `h.flags` 会有一个标志位来标识是否是 sameSizeGrow
- `h.B += bigger`，同时将原 `h.buckets` 指向的桶数组放到 `h.oldbuckets` 中，使用新的 `h.B` 创建新的桶数组并将其引用存储到 `h.buckets` 字段
  - 可以看出，如果触发原因是溢出桶数量过多，重建后新的桶数组不变，而如果是负载因子过大触发重建，新的桶数组长度会是原来的 2 倍
- 更新迁移进度 `h.nevacuate = 0`，溢出桶数量 `h.noverflow = 0`
- 如果 map 原本有溢出桶
  - 将 `h.extra.oldoverflow = h.extra.overflow`，同时 `h.overflow = nil`
- 如果本次重建时提前创建了溢出桶，则更新 `h.extra.nextOverflow` 指向这些新的溢出桶

`runtime.hashGrow()` 只是创建了新的桶数组，数据迁移的逻辑在 `runtime.growWork()`、`runtime.evacuate()` 中，整个迁移过程遵循 Copy On Write 原则，只有在真正赋值的时候，才会选择是否进行数据迁移。主要逻辑有：

- 从 `h.oldbuckets` 中找到当前需要迁移的是哪个桶，并计算重建之前桶的数量 newbit
- 使用 x、y 分别存储 sameSizeGrow 和 非 sameSizeGrow 时数据迁移后的目标位置
- 遍历第一步找到的桶及其溢出桶，对其中的数据进行迁移
  - 如果是非 sameSizeGrow 的迁移，是需要 rehash 重新计算存储桶的位置
- 更新迁移进度 `h.nevacuate`

注：如果是 sameSizeGrow，数据所在的新桶和旧桶的索引相同，所以不用 rehash 重新计算存储桶的位置，不过其元素会紧密排列从而提高桶的利用率。

## 删除

- `delete(m, key)` 底层实际调用了 `runtime.mapdelete()`

主要逻辑有：

- 判断是否处于写状态，是的话会报错
- 更新 `h.flags` 为正在写状态
- 找到目标桶的位置 bucket
- 判断 map 是否正在重建，如果是，先完成当前桶的重建过程
- 找到目标桶 b，计算高 8 位 hash
- 遍历目标桶及其溢出桶，找到要删除的 key
- 清空数据，同时将当前对应的 tophash 值设置为 `emptyOne`，如果发现后面没有元素，则将当前对应的 tophash 值设置为 `emptyRest`，并循环向上检查前一个元素是否为空，将连续没有元素的多个 tophash 都设置为 `emptyRest`

## 线程安全

如何实现线程安全的 map 类型？

- 加读写锁，扩展 map，见 [RWMap](examples/hash/rwMap.go)
  - 大量并发读写情况下，锁竞争会非常激烈
- 分片加锁，更高效的并发 map，见 [concurrent map](https://github.com/orcaman/concurrent-map)
  - 减少锁的粒度和锁的持有时间

### sync.Map

仅在以下两种场景使用 sync.Map 会比 map+RWMutex 性能高：

1. 只会增长的缓存系统，一个 key 只写入一次但会被读很多次
2. 多个 goroutine 为不相交的 key 集合进行读写操作

生产中很少使用。