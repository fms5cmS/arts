
# MySQL 持久化

MySQL 中一共有三种日志：

- binlog，所有存储引擎都可以使用的**逻辑日志**！记录了"ID=2 这一行的 c 字段加一"这样的原始逻辑，**只能追加写入**，达到一定大小后会更换日志文件
- redolog，InnoDB 特有的物理日志，记录了"在某个数据页做了什么操作"，**空间固定，循环写入**。为了保证即使数据库异常重启，之前提交的记录也不会丢失
  - 记录的内容类似于：将第 0 号表空间第 100 号页面中偏移量未 1000 处的值更新为 2
- undolog，每条记录在更新时会记录一条回滚操作，当没有事务再需要用到这些回滚日志时，系统会自动删除。主要用于实现 [MVCC](./04_transaction.md#mvcc)。

其中 redolog 是用来保证 MySQL 持久化功能的。

## WAL 以及 redolog 的 crash-safe 能力

在 MySQL 中，如果每一次更新操作都需要写入磁盘，然后磁盘也要找到对应的记录后再更新，这样的话整个过程的 IO 成本、查找成本都很高，

> 一个事务可能包含很多语句，涉及多个数据页（一条语句可能也会同时修改系统页面属性、索引页等），且这些数据页可能不相邻，这就意味着如果在将某个事务所有修改过的内存中的页面刷新到磁盘时，需要进行很多的随机 I/O。

为了解决上面的问题，MySQL 使用了 **WAL(Write-Ahead Logging) 技术，其关键点在于先写日志再写磁盘**。 不用每一次操作都实时把数据写盘，就算 crash 后也可以通过 redolog 恢复，所以能够实现快速响应 SQL 语句。

> 在执行事务过程中，每执行一条语句，就可能产生多条 redolog，这些 log 是按照产生顺序写入磁盘的，使用的是顺序 I/O。注意，这里指的是写入 redolog 文件中是顺序 I/O，而不是指的将数据刷新到数据页的磁盘空间。

执行事务的时候，InnoDB 引擎会**先把记录更新到内存并写入 redolog 中，此时，事务就算完成了**。InnoDB 引擎会在适当的时候（系统比较空闲时）再将这个操作记录更新到磁盘中。

如果在写入磁盘之前 crash 了，可以依赖日志来恢复数据页。有了 redolog，InnoDB 就可以保证即使数据库异常重启了，之前提交的记录也不会丢失，这个能力称为 **crash-safe**。

> binlog 是不具备 crash-safe 能力的

```sql
begin;
insert into table1 ...;
insert into table2 ...;
commit;
```

补充：执行事务的时候，InnoDB 引擎会先把 redo 日志写入到 redolog buffer 中，当 `commit` 的时候再真正把日志写入到 redolog 文件中。其中，redolog buffer 是一块用来暂存 redo 日志的内存。

> redolog 是固定大小的，如可以配置一组 4 个文件，每个文件 1GB，那么 redolog 总共就可以记录 4GB 的操作，且是循环写入的
> write pos，当前记录的位置，一边写一边后移，写到最后一个文件的末尾后回到 0 号文件开头；
> checkpoint，当前需要擦除的位置，也是向后推移并循环的，擦除记录前要把记录更新到数据文件中！
> 当 write pos 追上 checkpoint 时，就表示 redolog 写满了，无法再执行新的更新操作，需要停下来先擦除一些记录。

## 两阶段提交

以一个 update 语句为例：

1. 执行器先从引擎中拿到这条记录
2. 执行器对这条记录更新，再调用引擎接口写入更新后的新数据
3. 引擎将这条数据更新到内存中，同时将更新操作记录到 redolog 中，然后告知执行器完成，随时可以提交事务（此时 redo log 处于 prepare 状态）
4. 执行器生成这个操作的 binlog，并将 binlog 写入磁盘
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redolog 改成提交（commit）状态，更新完成

上面最后三步就是两阶段提交，将 redolog 的写入拆分成了 prepare 和 commit 两个阶段。

> 数据库的恢复
> 首先找到最近一次的全量备份，从这个备份恢复到临时库；
> 然后，从那个全量备份的时间点开始，将备份的 binlog 依次取出来，重放即可。
> 不只是误操作后需要恢复数据，当需要扩容，多搭建一些备库增加系统的读能力时，常用做法也是使用全量备份+binlog 实现的。
> 两阶段提交保证了主库和备库的数据一致性

使用两阶段提交的过程中如果发生了 crash：

- 第三步完成，第四步未完成时 crash

此时，redolog 处于 prepare 状态还未提交，binlog 尚未写入。崩溃恢复时，该操作并不会执行完成，由于 binlog 尚未写入，即使用来恢复数据也不会包含本次操作。

- 第四步完成，第五步未完成时 crash

此时，binlog 写完，redolog 尚未提交。崩溃恢复时，由于 redolog 未提交，所以会回滚事务（更新操作本身就是一个事务）。

如果不使用两阶段提交，那么数据库的状态就可能和使用日志恢复出来的库的状态不一致：

- 先写 redolog 后写 binlog，假设 redolog 写完，但 binlog 未写完的时候，MySQL 进程异常重启了。

由于 redolog 具有 crash-safe 的能力，所以可以完成数据恢复，但是 binlog 在未写完的情况下就 crash 了，所以 binlog 是无法恢复出数据的更新的。之后如果使用这个 binlog 做临时库的数据恢复的话，就会缺失数据了。

- 先写 binlog 后写 redolog，假设在 binlog 写完后 crash

由于 redolog 还没写，崩溃后这个更新是无效的，但是 binlog 已经记录了更新的操作。之后如果使用 binlog 来恢复的时候，就会比原库多出来一次更新。

## 两个相关配置

- `innodb_flush_log_at_trx_commit=1` 表示每次事务的 redolog 都直接持久化到磁盘，这样可以保证 MySQL 异常重启后数据不丢失
- `sync_binlog=1` 表示每次事务的 binlog 都持久化到磁盘，这样可以保证 MySQL 异常重启后 binlog 不丢失

## 只要 redolog 不要 binlog？

binlog 有 redolog 无法替代的能力

- 归档，redolog 时循环写入的，历史日志无法保留
- MySQL 高可用的基础就是 binlog 复制，且有些异构服务（如数据分析系统）是靠消费 MySQL 的 binlog 来更新自己的数据

# Redis 持久化

Redis 的持久化机制有两种：AOF、RDB。

默认持久化方式为 RDB，如果同时开启两种方式，优先启动 AOF 文件来恢复数据。

> 补充：
> fork 操作本身会阻塞主进程，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork 阻塞时间越久。
> fork 利用了操作系统提供的 Copy-On-Write 机制，当父进程对一个已经存在的 key 进行操作时，父进程会真正拷贝这个 key 对应的内存数据，申请新的内存空间，这样逐渐分离父子进程的内存数据，各自逐渐有自己独立的内存空间
> 注意：父进程 Copy-On-Write 复制数据时，复制的粒度是一个内存页（默认 4KB），如果父进程操作一个大的 key，申请大块内存耗时会变长，可能导致阻塞。

Redis 的持久化方案无法完全保证数据不丢失，所以 Redis 也无法保证事务的持久性。

## AOF

所有的写操作记录以 Redis 命令请求协议的格式完全持久化存储保存为 aof 文件。

- AOF 日志根据配置可能在在主线程中执行也可能在异步线程执行，**先执行命令，把数据写入内存，再记录日志**。

> 为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。 
> 由于是在当前命令后写日志，所以不会阻塞当前写操作
> 潜在风险：
> 执行命令成功但日志写入失败。Redis 做缓存的话还可以从后端读数据库恢复数据，如果是做数据库的话就无法用日志恢复了
> 如果在把日志文件写入磁盘时，磁盘写压力大，就会导致写盘很慢，进而阻塞后续写操作

- 追加模式写入
- 支持重写
- 三种写回策略
  - `always`，每个写命令执行完后立即将日志写回磁盘。在主进程进行，会影响主进程性能
  - `no`，每个写命令执行完成，先将日志写入 AOF 文件的内存缓冲区，落盘时机由 OS 决定
  - `everysec`，每个写命令执行完成，先将日志写入 AOF 文件的内存缓冲区，每隔 1s 会进行一次落盘。异步线程完成

aof 文件过大，继续追加命令记录的话效率会变低，且发生宕机后，故障恢复会很慢。所以提供了 AOF 重写机制。将过大的 aof 文件中的命令进行合并重写。

重写过程是由主进程 fork 出的后台子进程 bgrewriteaof 来完成的，是为了避免阻塞主线程，导致数据库性能下降。

> fork 会把主线程的数据结构（含内存页表）拷贝一份给 bgrewriteaof 子进程，也就能共享访问父进程的内存数据了。注意，Redis 实例内存越大，内存页表拷贝也会越耗时，而这个过程是阻塞父进程的！ 
> 然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把数据写成操作，记入重写日志。

因为重写过程主线程未阻塞，仍然可以处理新来的操作，此时如果有新来的写操作，日志会被主线程写到两个地方：
- 正在使用的 aof 日志，新来的操作会被写到它的缓冲区.即使宕机了，这个 aof 日志的操作仍是齐全的，可以用来恢复
- 新的 aof 重写日志，新来的操作也会被写到重写日志的缓冲区 
  - 等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 aof 文件，以保证数据库最新状态的记录

AOF 重写为什么不复用 AOF 本身的日志？

1. 父子进程会产生数据竞争问题，解决竞争问题就会影响父进程的性能
2. 如果 AOF 重写失败，原本的 AOF 文件就相当于被污染了，无法做恢复使用

> AOF文件中key的过期时间会保存为绝对时间，在恢复时会以绝对的过期时间写入，如果 key 已经过期，恢复时 Redis 不会为其分配空间

## RDB

全量快照的方式记录内存中所有 k-v 对，然后将其写入一个临时文件，持久化结束后用这个临时文件替换之前的持久化文件。

- 性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 Redis 的高性能
- 数据量大时，比 AOF 启动效率高
- 能在指定时间间隔对数据进行快照存储，但安全性较低，如果持久化期间发生故障会发生数据丢失

Redis 提供了两个命令来生成 RDB 文件：

- `save`：在主进程中执行，会导致阻塞
- `bgsave`：创建子进程专门写入 RDB 文件，避免了主进程的阻塞

> 使用 `bgsave` 命令通过 fork 出子进程来生成快照的方式是借助了 OS 提供的 Copy-On-Write 机制，即使主进程要修改某个 key 的数据，主进程也会先申请内存复制一份数据，然后在这个副本数据上进行修改。

为了尽可能减少数据的丢失，也不能频繁的快照，那该怎么办呢？可以做增量快照！ 做了一次全量快照后，后续的快照只对修改的数据进行快照记录，这样可以避免每次全量快照的开销。

而记住哪些数据被修改，又需要使用额外的元数据信息去记录，会带来额外的空间开销，如果键值很小的话，这些额外的元数据信息反而需要较大的内存，就得不偿失了。

Redis 提出了一种混合使用 AOF 日志和内存快照的方法。

## 混合持久化

内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。

> 快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。
> AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销

混合持久化工作在 AOF 日志重写过程，当开启了混合持久化，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。

重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样加载的时候速度会很快。加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得数据更少的丢失。

# Kafka 持久化

Kafka 是在 Broker 上通过消息日志（Log）来保存数据的，每个日志就是磁盘上一个只能追加写入消息的物理文件。

> 只能追加写入，避免了缓慢的随机 I/O 操作，改为性能较高的顺序 I/O 写操作。


